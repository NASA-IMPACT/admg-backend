{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from config.server import (client_id, client_secret, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pickle.load(open('ingest_data/db_10_camp','rb')) # fresh_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key_map = json.load(open(\"config/mapping_primary.json\"))\n",
    "ingest_order = json.load(open(\"config/ingest_order.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this stuff shouldn't be ingested anyway, what is it?\n",
    "\n",
    "# db[\"campaign\"][db[\"campaign\"][\"short_name\"] == \"OLYMPEX\"].iloc[0][\"ignore_number_deployments\"] = 58\n",
    "# db[\"campaign\"][db[\"campaign\"][\"short_name\"] == \"OLYMPEX\"].iloc[0][\"ignore_number_deployments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Bad and Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['collection_period']['auto_generated']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove gcmd_project short_name duplicates \n",
    "db[\"gcmd_project\"].drop_duplicates(subset =\"short_name\", keep = False, inplace = True)\n",
    "\n",
    "# remove missing instrument.short_name\n",
    "# db[\"instrument\"] = db[\"instrument\"][db[\"instrument\"][\"short_name\"] != \"Information Not Available\"]\n",
    "\n",
    "#TODO: this should ingest as the default null value\n",
    "# change nan to 0 \n",
    "db[\"campaign\"][\"number_collection_periods\"] = db[\"campaign\"][\"number_collection_periods\"].fillna(0)\n",
    "db[\"campaign\"][\"number_data_products\"] = db[\"campaign\"][\"number_data_products\"].fillna(0)\n",
    "\n",
    "# there is missing data for campaign.ongoing, fill all in to False\n",
    "db[\"campaign\"][\"ongoing\"] = db[\"campaign\"][\"ongoing\"].fillna(False)\n",
    "\n",
    "# there is missing data for deployment.number_flights, fill all in to 0\n",
    "db[\"deployment\"][\"number_flights\"] = db[\"deployment\"][\"number_flights\"].fillna(0)\n",
    "\n",
    "# correct column naming in collection_period table\n",
    "db['collection_period'].rename(columns={'instrument':'foreign-instrument-short_name'}, inplace=True)\n",
    "\n",
    "# correct column naming in collection_period table\n",
    "db['instrument_type'].rename(columns={'foreign-platform_type-short_name':'foreign-instrument_type-short_name'}, inplace=True)\n",
    "\n",
    "# filter out non-matching short_names\n",
    "# db['collection_period'] = db['collection_period'][db['collection_period']['foreign-instrument-short_name'] != 'Information Not Available']\n",
    "# db['collection_period']= db['collection_period'][db['collection_period']['foreign-instrument-short_name']!='NAWX radar']\n",
    "# db['collection_period']= db['collection_period'][db['collection_period']['foreign-instrument-short_name']!='Electric Field Mill']\n",
    "# db['collection_period']= db['collection_period'][db['collection_period']['foreign-instrument-short_name']!='EFCS (GSFC and MSFC versions)']\n",
    "\n",
    "# TODO: why does this field exist at all?\n",
    "# fill in missing number of flights \n",
    "db['collection_period'][\"number_collection_periods\"] = db['collection_period'][\"number_collection_periods\"].fillna(0)\n",
    "\n",
    "# fill in missing tail numbers\n",
    "db['collection_period'][\"platform_identifier\"] = db['collection_period'][\"platform_identifier\"].fillna(0)\n",
    "\n",
    "# create a valid deployment short name\n",
    "db['collection_period']['foreign-deployment-short_name']=db['collection_period']['foreign-campaign-short_name']+'_'+db['collection_period']['foreign-deployment-short_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Value Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_values(db, table_name, column, wrong_value, correct_value):\n",
    "    db[table_name][column]=db[table_name][column].apply(lambda x: x if x!=wrong_value else correct_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'campaign',\n",
    "    column = 'number_collection_periods',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'iop',\n",
    "    column = 'region_description',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Undisclosed Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove multiple gcmd links. This will need to be properly implemented in the future\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'platform_type',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '227d9c3d-f631-402d-84ed-b8c5a562fc27, 06e037ed-f463-4fa3-a23e-8f694b321eb1',\n",
    "    correct_value = '227d9c3d-f631-402d-84ed-b8c5a562fc27')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'platform_type',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '57b7373d-5c21-4abb-8097-a410adc2a074, 491d3fcc-c097-4357-b1cf-39ccf359234, 2219e7fa-9fd0-443d-ab1b-62d1ccf41a89',\n",
    "    correct_value = '57b7373d-5c21-4abb-8097-a410adc2a074')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument_type',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '3d25724b-832f-4a61-b0b2-4f2ccecdba94, ebfff02c-2e5a-476e-aafb-c00167bf2daa,  def72d78-3c2f-4f46-91e7-259a0e63e2de',\n",
    "    correct_value = '3d25724b-832f-4a61-b0b2-4f2ccecdba94')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument_type',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '78c70202-ab05-40d6-90db-563be2a8dc90, 2315cd93-18c9-4553-a7d2-650d65d95505',\n",
    "    correct_value = '78c70202-ab05-40d6-90db-563be2a8dc90')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument_type',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '2724649a-5bae-4b34-89c0-2e5ca6d3203b, 02a7fb42-6ff5-493f-a447-b687f841b2c1, b5d7c2cb-60c4-4dfe-bdc9-31e9fcc97dd0',\n",
    "    correct_value = '2724649a-5bae-4b34-89c0-2e5ca6d3203b')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'geographical_region',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = 'd40d9651-aa19-4b2c-9764-7371bb64b9a7, 3fedcf7c-7b0c-4b51-abd2-2c54de713061',\n",
    "    correct_value = 'd40d9651-aa19-4b2c-9764-7371bb64b9a7')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'geophysical_concept',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '0611b9fd-fd92-4c4d-87bb-bc2f22c548bc, 4dd22dc9-1db4-4187-a2b7-f5b76d666055',\n",
    "    correct_value = '0611b9fd-fd92-4c4d-87bb-bc2f22c548bc')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'geophysical_concept',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = 'c9e429cb-eff0-4dd3-9eca-527e0081f65c, 62019831-aaba-4d63-a5cd-73138ccfa5d0',\n",
    "    correct_value = 'c9e429cb-eff0-4dd3-9eca-527e0081f65c')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'geophysical_concept',\n",
    "    column = 'gcmd_uuid',\n",
    "    wrong_value = '0af72e0e-52a5-4695-9eaf-d6fbb7991039, 637ac172-e624-4ae0-aac4-0d1adcc889a2',\n",
    "    correct_value = '0af72e0e-52a5-4695-9eaf-d6fbb7991039')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplement missing instrument data\n",
    "# inventory team needs to actually fill this stuff out correctly\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'table-measurement_region-short_name',\n",
    "    wrong_value = 'troposphere',\n",
    "    correct_value = 'Troposphere')\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument-to-measurement_region',\n",
    "    column = 'measurement_region',\n",
    "    wrong_value = 'troposphere',\n",
    "    correct_value = 'Troposphere')\n",
    "#---------------------------\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'technical_contact',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake Contact')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'spatial_resolution',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake spatial_resolution')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'temporal_resolution',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake temporal_resolution')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'radiometric_frequency',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake radiometric_frequency')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'description',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake description')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'long_name',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Fake long_name')\n",
    "\n",
    "\n",
    "# -------\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument-to-instrument_type',\n",
    "    column = 'instrument_type',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'In Situ - Magnetic/Electric')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument-to-gcmd_phenomena',\n",
    "    column = 'gcmd_phenomena',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = '1212')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument-to-measurement_region',\n",
    "    column = 'measurement_region',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Troposphere')\n",
    "\n",
    "# -------\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'table-instrument_type-short_name',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'In Situ - Magnetic/Electric')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'table-gcmd_phenomena-ignore_code',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = '1212')\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'instrument',\n",
    "    column = 'table-measurement_region-short_name',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'Troposphere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplement gcmd_platform\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'gcmd_platform',\n",
    "    column = 'description',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'fake description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add instrument and gcmd phenomena pairs to the instrument-to-gcmd_phenomena where they are missing, because this\n",
    "# is a requried field and I don't want to change the models\n",
    "for instrument in db['instrument']['short_name']:\n",
    "    bool_list = list(db['instrument-to-gcmd_phenomena']['instrument']==instrument)\n",
    "    if sum(bool_list)==0:\n",
    "        db['instrument-to-gcmd_phenomena']=db['instrument-to-gcmd_phenomena'].append(\n",
    "            {'instrument':instrument, 'gcmd_phenomena':'1212'}, \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "for instrument in db['instrument']['short_name']:\n",
    "    bool_list = list(db['instrument-to-measurement_region']['instrument']==instrument)\n",
    "    if sum(bool_list)==0:\n",
    "        db['table-measurement_region-short_name']=db['table-measurement_region-short_name'].append(\n",
    "            {'instrument':instrument, 'measurement_region':'Troposphere'}, \n",
    "            ignore_index=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplement platform values\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'platform',\n",
    "    column = 'description',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'fake description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplement campaign values\n",
    "\n",
    "correct_values(\n",
    "    db=db,\n",
    "    table_name = 'campaign',\n",
    "    column = 'nasa_led',\n",
    "    wrong_value = 'Information Not Available',\n",
    "    correct_value = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a mapping error\n",
    "# should be able to remove next time I run\n",
    "db['iop'].rename(columns={'Start': 'start_date'}, inplace=True)\n",
    "\n",
    "db['significant_event'].rename(columns={'Start': 'start_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_values(\n",
    "#     db=db,\n",
    "#     table_name = 'collection_period',\n",
    "#     column = 'foreign-deployment-short_name',\n",
    "#     wrong_value = 'OLYMPEX_dep_2016',\n",
    "#     correct_value = 'OLYMPEX_dep_2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete collection periods from Olympex that had no instruments on the platforms....\n",
    "# db['collection_period'] = db['collection_period'][db['collection_period']['short_name']!='OLYMPEX_dep_2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly Order Heirarchical Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest these first\n",
    "first = db['platform_type'][db['platform_type']['foreign-platform_type-short_name']=='none']\n",
    "\n",
    "# ingest these second\n",
    "second = db['platform_type'][db['platform_type']['foreign-platform_type-short_name']!='none']\n",
    "\n",
    "# correctly ordered\n",
    "db['platform_type'] = pd.concat([first, second])\n",
    "\n",
    "# ingest these first\n",
    "first = db['instrument_type'][db['instrument_type']['foreign-instrument_type-short_name']=='none']\n",
    "\n",
    "# ingest these second\n",
    "second = db['instrument_type'][db['instrument_type']['foreign-instrument_type-short_name']!='none']\n",
    "\n",
    "# correctly ordered\n",
    "db['instrument_type'] = pd.concat([first, second])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ping admg.nasa-impact.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to get the acess token for using the api\n",
    "\n",
    "server = 'http://admg.nasa-impact.net'\n",
    "# server = 'http://localhost:8000'\n",
    "base_url = f'{server}/api/'\n",
    "\n",
    "url = f'{server}/authenticate/token/'\n",
    "\n",
    "response = requests.post(url, data=data, auth=(client_id, client_secret))\n",
    "access_token = json.loads(response.text)['access_token']\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {access_token}',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api(url):\n",
    "    url = f'{base_url}{url}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell if you are rerunning the ingest halfway throught\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreign Key Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_map = True\n",
    "\n",
    "if reset_map:\n",
    "    foreign_key_uuid_map = {\n",
    "        'platform_type': {},\n",
    "        'home_base': {},\n",
    "        'repository': {},\n",
    "        'focus_area': {},\n",
    "        'season': {},\n",
    "        'instrument_type': {},\n",
    "        'measurement_region': {},\n",
    "        'geographical_region': {},\n",
    "        'geophysical_concept': {},\n",
    "        'campaign': {},\n",
    "        'platform': {},\n",
    "        'instrument': {},\n",
    "        'deployment': {},\n",
    "        'iop': {},\n",
    "        'significant_event': {},\n",
    "        'partner_org': {},\n",
    "        'collection_period': {},\n",
    "        'gcmd_phenomena': {},\n",
    "        'gcmd_project': {},\n",
    "        'gcmd_platform': {},\n",
    "        'gcmd_instrument': {},\n",
    "        'measurement_keywords': {},\n",
    "    }   \n",
    "else:\n",
    "    foreign_key_uuid_map = pickle.load(open('foreign_key_uuid_map','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_api(table_name, data):\n",
    "    \"\"\"\n",
    "    Takes a table_name and a line of data, and adds it to the database.\n",
    "    Stores the generated UUID into the foreign_key_uuid_map for later use.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # handle the spelling misphaps of respository...\n",
    "    # I think this needs to be a permanent change?\n",
    "    if data.get('repositorys'):\n",
    "        data['repositories'] = data.pop('repositorys')\n",
    "    \n",
    "    \n",
    "    print('\\n ----- Calling API')\n",
    "    \n",
    "    post_url = f'{base_url}{table_name}'\n",
    "    something_response = requests.post(post_url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "    if '\"success\": false' in something_response.text and 'this short name already exists' in something_response.text:\n",
    "        return f'the following entry already existed {table_name=} {data=}'\n",
    "\n",
    "\n",
    "    print(f'{table_name=}, {data=}')\n",
    "    print(f'{something_response.text=}')\n",
    "    uuid = something_response.text.split(':')[4].strip().split(' ')[0]\n",
    "    requests.post(f'{base_url}change_request/{uuid}/push', headers=headers).text\n",
    "    approved = json.loads(requests.post(f'{base_url}change_request/{uuid}/approve', headers=headers).text)\n",
    "    print(f'{approved=}')\n",
    "    \n",
    "    # put the uuid obtained as the uuid for the primary value of the data\n",
    "    primary_key = primary_key_map[table_name] # gets the correct column, usually short_name\n",
    "    primary_value = data[primary_key] # finds the actual value for the primary key, usually the short_name\n",
    "    foreign_key_uuid_map[table_name][primary_value] = approved[\"data\"][\"action_info\"][\"uuid_changed\"]\n",
    "    \n",
    "    return approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ignored_data(data):\n",
    "    print('\\n ----- Removing Ignored Data')\n",
    "    \n",
    "    retval = {}\n",
    "    for key, value in data.items():\n",
    "        if key == \"ignore_code\":\n",
    "            retval[key] = value\n",
    "        elif 'ignore' not in key:\n",
    "            retval[key] = value\n",
    "        \n",
    "        try:\n",
    "            if np.isnan(value):\n",
    "                retval[key] = 0\n",
    "        except Exception:\n",
    "            pass \n",
    "        \n",
    "        if isinstance(value, datetime.datetime):\n",
    "            retval[key] = value.isoformat().split('T')[0]\n",
    "            \n",
    "            \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ignore_tables = [\n",
    "#     \"instrument-to-instrument_type\",\n",
    "#     \"instrument-to-measurement_keywords\",\n",
    "#     \"instrument-to-gcmd_instrument\"\n",
    "# ]\n",
    "\n",
    "def resolve_many_to_many_keys(table_name, data):\n",
    "    print('\\n ----- Resolving Many to Many')\n",
    "    \n",
    "    # data should be json of the row\n",
    "   \n",
    "    primary_key = primary_key_map[table_name]\n",
    "    primary_value = data[primary_key]\n",
    "    tables = [key for key in db[table_name].keys() if \"table-\" in key]\n",
    "    \n",
    "    print(f'{primary_key=}')\n",
    "    print(f'{primary_value=}')\n",
    "    print(f'{tables=}')\n",
    "    \n",
    "    print('foriegn info -----')\n",
    "    for table in tables:\n",
    "        _, foreign_table, foreign_key = table.split(\"-\")\n",
    "        linking_table = f\"{table_name}-to-{foreign_table}\"\n",
    "#         if linking_table not in ignore_tables:\n",
    "#         print(linking_table, table_name, primary_value, foreign_table)\n",
    "        foreign_values = db[linking_table][db[linking_table][table_name] == primary_value][foreign_table]\n",
    "        mapped_uuids = [\n",
    "            foreign_key_uuid_map[foreign_table][val] \n",
    "                for val in foreign_values \n",
    "                    if val != \"Information Not Available\" and foreign_key_uuid_map[foreign_table].get(val)\n",
    "        ]\n",
    "        data[f\"{foreign_table}s\"] = mapped_uuids\n",
    "        if data.get(table):\n",
    "            del data[table]\n",
    "            \n",
    "        print(f'{foreign_table=}')\n",
    "        print(f'{foreign_key=}')\n",
    "        print(f'{linking_table=}')\n",
    "        print(f'{foreign_values=}')\n",
    "        print(f'{mapped_uuids=}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resolve_foreign_keys(table_name, data):\n",
    "#     # data should be json of the row\n",
    "#     fields = [key for key in data.keys() if \"foreign-\" in key]\n",
    "#     for field in fields:\n",
    "#         _, foreign_table, foreign_key = field.split(\"-\")\n",
    "#         if table_name in [\"platform_type\", \"instrument_type\"]:\n",
    "#             pass\n",
    "#         else:\n",
    "#             foreign_value = data[field]\n",
    "#             if foreign_key_uuid_map[foreign_table].get(foreign_value):\n",
    "#                 mapped_uuid = foreign_key_uuid_map[foreign_table][foreign_value]      \n",
    "#                 data[foreign_table] = mapped_uuid\n",
    "#         del data[field]\n",
    "        \n",
    "def resolve_foreign_keys(table_name, data):\n",
    "    print('\\n ----- Resolving Foreign Keys')\n",
    "    # data should be json of the row\n",
    "    fields = [key for key in data.keys() if \"foreign-\" in key]\n",
    "    for field in fields:\n",
    "      \n",
    "        _, foreign_table, foreign_key = field.split(\"-\")\n",
    "        foreign_value = data[field]\n",
    "        \n",
    "        print()\n",
    "        print(f'{foreign_value=}')\n",
    "        print(f'{fields=}')\n",
    "        \n",
    "        if foreign_key_uuid_map[foreign_table].get(foreign_value):\n",
    "            mapped_uuid = foreign_key_uuid_map[foreign_table][foreign_value]   \n",
    "            if foreign_table in ['platform_type', 'instrument_type']:\n",
    "                foreign_table='parent'\n",
    "            data[foreign_table] = mapped_uuid\n",
    "        del data[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nones(data):\n",
    "    print('\\n ----- Removing Nones')\n",
    "    return {key:value for key, value in data.items() if value != 'none' and value != \"Information Not Available\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest_order = [\n",
    "#  'platform_type',\n",
    "# #  'instrument_type',\n",
    "# #  'home_base',\n",
    "# #  'repository',\n",
    "# #  'focus_area',\n",
    "# #  'season',\n",
    "# #  'measurement_region',\n",
    "# #  'geographical_region',\n",
    "# #  'geophysical_concept',\n",
    "# #  'gcmd_phenomena',\n",
    "# #  'gcmd_instrument',\n",
    "# #  'gcmd_platform',\n",
    "# #  'gcmd_project',\n",
    "# #  'partner_org',\n",
    "# #  'instrument',\n",
    "# #  'platform',\n",
    "# #  'campaign',\n",
    "# #  'deployment',\n",
    "# #  'iop',\n",
    "# #  'significant_event'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ingests everything except for collection period\n",
    "\n",
    "with open(\"result.txt\", \"w\") as f:\n",
    "    for table_name in ingest_order:\n",
    "    # for table_name in [\"platform_type\"]:\n",
    "        for index, row in db[table_name].iterrows():\n",
    "            print(table_name, index)\n",
    "            api_data = row.to_dict()\n",
    "            print(api_data)\n",
    "            api_data = remove_ignored_data(api_data)\n",
    "            api_data = remove_nones(api_data)\n",
    "            primary_key = primary_key_map[table_name]\n",
    "            primary_value = api_data.get(primary_key)\n",
    "            if primary_value:\n",
    "                resolve_many_to_many_keys(table_name, api_data)\n",
    "                resolve_foreign_keys(table_name, api_data)\n",
    "                result = call_api(table_name, api_data)\n",
    "                f.write(f\"{json.dumps(result)}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{table_name}: {primary_key}, {json.dumps(api_data)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['instrument'][db['instrument']['short_name']=='DIAL']['table-instrument_type-short_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(db['instrument'][db['instrument']['short_name']=='CoSMIR']['table-measurement_region-short_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"result.txt\", \"w\") as f:\n",
    "    temp_short_name = db[\"collection_period\"].iloc[0][\"short_name\"]\n",
    "    temp = {}\n",
    "    rows = []\n",
    "    for index, row in db[\"collection_period\"].iterrows():\n",
    "        dict_row = row.to_dict()\n",
    "        if temp_short_name != dict_row[\"short_name\"]:\n",
    "            rows.append(temp)\n",
    "            temp = {}\n",
    "            temp_short_name == dict_row[\"short_name\"]\n",
    "\n",
    "        api_data = remove_ignored_data(dict_row)\n",
    "        api_data = remove_nones(dict_row)\n",
    "        resolve_foreign_keys(\"collection_period\", api_data)\n",
    "        \n",
    "        temp = {\n",
    "            **temp, \n",
    "            **api_data, \n",
    "            \"instruments\": [\n",
    "                *temp.get(\"instruments\", []),\n",
    "                api_data.get(\"instrument\")\n",
    "            ]\n",
    "        }\n",
    "        if temp.get(\"instrument\"):\n",
    "            del temp[\"instrument\"]\n",
    "#     rows=[row for row in rows if len(row['instruments'])<1]\n",
    "#     print(rows)\n",
    "    for row in rows:\n",
    "#         print(row,'\\n')\n",
    "#         print(row)\n",
    "        row[\"instruments\"] = [val for val in row[\"instruments\"] if val is not None]\n",
    "        if len(row[\"instruments\"]) == 0:\n",
    "            continue\n",
    "        result = call_api(\"collection_period\", row)\n",
    "        f.write(f\"{json.dumps(result)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([i.short_name for i in Instrument.object.all()] ).difference(set(foreign_key_uuid_map[\"instrument\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(foreign_key_uuid_map, open('foreign_key_uuid_map','wb'))\n",
    "json.dump(foreign_key_uuid_map, open(\"foreign_key_uuid_map.json\", \"w\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# TODO: ADD THIS TO THE INGEST VALIDATION FILE #\n",
    "################################################\n",
    "\n",
    "errors = validate.foriegn_keys(db, \n",
    "                                data_table='collection_period', \n",
    "                                data_index='short_name', \n",
    "                                data_column='foreign-deployment-short_name', \n",
    "                                foriegn_table='deployment', \n",
    "                                foriegn_column='short_name')\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = validate.foriegn_keys(db, \n",
    "                                data_table='collection_period', \n",
    "                                data_index='short_name', \n",
    "                                data_column='foreign-instrument-short_name', \n",
    "                                foriegn_table='instrument', \n",
    "                                foriegn_column='short_name')\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['collection_period'][db['collection_period']['short_name']=='OLYMPEX_dep_2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(foreign_key_uuid_map, open('foreign_key_uuid_map', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
