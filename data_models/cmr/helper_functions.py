import json
import requests

from collections import namedtuple
from datetime import datetime
from io import BytesIO
from lxml import etree

from config import print_on as PRINT_ON


def custom_print(obj=None):
    """Debugging print wrapper that can be used for optional print functionality. Note
    that this functions takes in the global variable PRINT_ON from the config
    file.

    Args:
        obj (obj): Any printable Python object
    """

    if PRINT_ON:
        if obj:
            print(obj)
        else:
            print()


def calculate_num_returned(num_hits, page_size, page_num):
    naive = page_size*page_num
    if naive < num_hits:
        num_returned = naive
    else:
        num_returned = num_hits % naive

    return num_returned


def ingest_xml(url):
    response = requests.get(url)  # , headers={'Connection': 'close'})
    rdf_file = BytesIO(response.content)
    tree = etree.parse(rdf_file)  # could fail for a lot of reasons
    return tree


def ingest_json(url):
    response = requests.get(url).text
    try:
        data = json.loads(response)
    except:
        data = None
    return data


def ingest_campaign(short_name):
    # TODO: handle a short_name that has no results

    # set initial variables
    page_num = 1
    page_size = 100
    campaign_trees = []
    finished = False

    while finished == False:  
        # make inital query and append results
        url = f'https://cmr.earthdata.nasa.gov/search/collections?'+\
            f'project={short_name}&'+\
            f'page_size={page_size}&'+\
            f'page_num={page_num}'
        campaign_tree = ingest_xml(url)
        campaign_trees.append(campaign_tree)
        
        # calculate num returned and iterate if needed
        num_hits = int(campaign_tree.find('hits').text)
        num_returned_naive = page_num*page_size
        if num_returned_naive < num_hits:
            page_num += 1
        else:
            finished = True

    return campaign_trees


def campaign_xlm_json(campaign_trees):

    campaign_metadata = []
    for campaign_tree in campaign_trees:
        for references in campaign_tree.findall('references'):
            for reference in references:

                name = reference.find('name').text
                concept_id = reference.find('id').text

                url = f'https://cmr.earthdata.nasa.gov/search/concepts/{concept_id}.umm-json'

                metadata = ingest_json(url)

                campaign_metadata.append({'name': name,
                                        'concept_id': concept_id,
                                        'metadata': metadata})

                custom_print(f'name: {name}')
                custom_print(f'    concept_id: {concept_id}')
                custom_print()
    return campaign_metadata


def extract_collection_periods(campaign_metadata):
    """Extracts platforms as a proxy for collection_periods and aggregates the metadata

    Args:
        campaign_metadata (dict): this is a custom dict generated by campagin_xlm_json

    Returns:
        dict: A dict containing each unique platform and its aggregated metadata, including
            DOIs, short and long names, platform identifiers, and instruments.
    """

    platforms = {}
    for data_product in campaign_metadata:

        for platform_info in data_product['metadata'].get('Platforms', [{}]):
            # generate reference name
            platform_short_name = platform_info.get('ShortName', '')
            platform_long_name = platform_info.get('LongName', '')

            platform_chars = campaign_metadata[1]['metadata']['Platforms'][0].get('Characteristics', [])
            platform_identifiers = [char.get('Value', '') for char in platform_chars if char.get('Name')=='AircraftID'] 
            
            platform_reference = '_&_'.join([platform_short_name, platform_long_name] + platform_identifiers)

            # get instruments
            instruments = {}
            if platform_info.get('Instruments'):
                for instrument_info in platform_info.get('Instruments', []):
                    instrument_short_name = instrument_info.get('ShortName', '')
                    instrument_long_name = instrument_info.get('LongName', '') 
                    instrument_reference = '_&_'.join([instrument_short_name, instrument_long_name])    

                    instruments[instrument_reference] = {
                        'short_name': instrument_short_name,
                        'long_name': instrument_long_name,
                    }

            if platforms.get(platform_reference):
                platforms[platform_reference]['instruments'] = {**platforms[platform_reference]['instruments'], **instruments}
                platforms[platform_reference]['dois'].append(data_product.get('DOI'))

            else:
                platforms[platform_reference]= {
                    'platform_names': {
                        'short_name': platform_short_name, 
                        'long_name': platform_long_name},
                    'platform_identifiers': platform_identifiers,
                    'instrument_information_source': 'cmr_api',
                    'auto_generated': True,
                    'instruments': instruments,
                    'dois': [data_product.get('DOI')]
                }
    
    return platforms


def date_overlap(cmr_start, cmr_end, dep_start, dep_end):

    Range = namedtuple('Range', ['start', 'end'])

    cmr_range = Range(start=cmr_start, end=cmr_end,)
    dep_range = Range(start=dep_start, end=dep_end)

    latest_start = max(cmr_range.start, dep_range.start)
    earliest_end = min(cmr_range.end, dep_range.end)

    delta = (earliest_end - latest_start).days + 1
    overlap = max(0, delta)

    return overlap


def date_filter(metadata, dep_start, dep_end):
    filtered_metadata = []
    for reference in metadata:
        TemporalExtents = reference['metadata'].get('TemporalExtents',[{}])[0]
        cmr_start = TemporalExtents.get('RangeDateTimes',[{}])[0].get('BeginningDateTime', 'error')
        cmr_end = TemporalExtents.get('RangeDateTimes',[{}])[0].get('EndingDateTime', 'error')

        cmr_start = datetime.strptime(cmr_start, '%Y-%m-%dT%H:%M:%S.%fZ')
        cmr_end = datetime.strptime(cmr_end, '%Y-%m-%dT%H:%M:%S.%fZ')

        days_overlapping = date_overlap(cmr_start, cmr_end, dep_start, dep_end)
        if days_overlapping > 0:
            filtered_metadata.append(reference)

    return filtered_metadata


def project_filter(metadata, short_name):
    # might not be necessary
    filtered_metadata = []
    for reference in metadata:
        projects = reference['metadata'].get('Projects', [])
        print(projects)
        print()
        for project in projects:
            project_short_name = project.get('ShortName', '')
            if short_name.lower() == project_short_name.lower():
                filtered_metadata.append(reference)
                break

    return filtered_metadata


def general_extractor(campaign_metadata, field):
    data = []
    for reference in campaign_metadata:
        value = reference['metadata'].get(field, '')
        if value:
            data.append(value)
    return data


def combine_spatial_extents(spatial_extents):
    # TODO: this should combine multiple spatial extents into a total coverage 
    pass
