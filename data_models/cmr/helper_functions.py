import json
import requests

from collections import namedtuple
from datetime import datetime
from io import BytesIO
from lxml import etree
from urllib.parse import urlencode

def calculate_num_returned(num_hits, page_size, page_num):
    """Calculates number of hits returned in the current CMR page

    Args:
        num_hits (int): num hits from api call metadata
        page_size (int): page size from user query
        page_num (int): page number from user query

    Returns:
        int: number of results on current page
    """

    # this function is no longer used, but it seemed like a waste to delete it
 
    num_returned = page_size * page_num
    if num_returned < num_hits:
        num_returned = num_hits % num_returned

    return num_returned


def ingest_xml(url):
    response = requests.get(url)
    rdf_file = BytesIO(response.content)
    tree = etree.parse(rdf_file)  # could fail for a lot of reasons
    return tree


def ingest_json(url):
    response = requests.get(url).text
    # TODO: address this in the testing
    try:
        data = json.loads(response)
    except:
        data = None
    return data


def ingest_campaign(short_name):
    """Queries CMR for a specific campaign/project short_name and aggergates
    all the granule metadata.

    Args:
        short_name (str): capaign/project short_name

    Returns:
        list: list of xml_trees
    """

    # set initial variables
    page_num = 1
    page_size = 100
    campaign_trees = []
    finished = False

    while not finished:  
        # make inital query and append results
        base_url = 'https://cmr.earthdata.nasa.gov/search/collections?'
        parameters = urlencode({'project': short_name,
                                'page_size': page_size,
                                'page_num': page_num})
        url = base_url + parameters

        campaign_tree = ingest_xml(url)
        campaign_trees.append(campaign_tree)
        
        # calculate num returned and iterate if needed
        num_hits = int(campaign_tree.find('hits').text)
        num_returned_naive = page_num*page_size
        if num_returned_naive < num_hits:
            page_num += 1
        else:
            finished = True

    return campaign_trees

def campaign_xml_to_json(campaign_trees):
    """Accepts campaign metadata in the form of a list of campaign_tree xml files
    and parses out the relevant information, aggregates the results, and converts
    to a python dictionary.

    Args:
        campaign_trees ([list]): List of campaign xlm files

    Returns:
        dict: Parsed dictionary of the original campaign xml files
    """

    concept_ids = []
    for campaign_tree in campaign_trees:
        for references in campaign_tree.findall('references'):
            for reference in references:
                concept_ids.append(reference.find('id').text)

    # set initial variables
    page_num = 1
    page_size = 100
    metadata = []
    finished = False

    while not finished:
        base_url = 'https://cmr.earthdata.nasa.gov/search/collections.umm_json?'
        parameters = urlencode({'echo_collection_id[]': concept_ids,
                                'page_size': page_size,
                                'page_num': page_num}, doseq=True)
        url = base_url + parameters

        data = ingest_json(url)
        metadata += [{'concept_id': entry['meta']['concept-id'], 'metadata': entry['umm']} for entry in data['items']]

        # calculate num returned and iterate if needed
        num_hits = int(data['hits'])
        num_returned_naive = page_num * page_size
        if num_returned_naive < num_hits:
            page_num += 1
        else:
            finished = True

    return metadata


def general_extractor(campaign_metadata, field):
    """Extracts and aggregates a specific top level item from the campaign_metadata.

    Args:
        campaign_metadata (dict): this is a custom dict generated by campagin_xml_json
        field (str): Key value for the desired field name

    Returns:
        list: Aggregated list of the values in the requested field.
    """

    data = []
    for reference in campaign_metadata:
        value = reference['metadata'].get(field, '')
        if value:
            data.append(value)
    return data


def extract_daacs(campaign_metadata):
    """Extracts and aggregates all the daacs from a single campaign.

    Args:
        campaign_metadata ([type]): [description]

    Returns:
        list: list of daac names
    """

    # TODO: inventory team should specify which role they are most concerned with
    role_filter=['ARCHIVER', 'DISTRIBUTOR', 'PROCESSOR', 'ORIGINATOR']

    mega_daac_list=general_extractor(campaign_metadata, 'DataCenters')
    daacs = [
        daac['ShortName']
            for daac_list in mega_daac_list
                for daac in daac_list
                    if daac['Roles'][0] in role_filter
            ]

    return daacs


def extract_region_description(campaign_metadata):
    """Extracts the GCMD LocationKeywords from the metadata. These will be
    used as a proxy for region_description at the campaign level.

    Args:
        campaign_metadata ([type]): [description]

    Returns:
        list: [{'Category': value, 'Type': value, 'Subregion1': value, 'Subregion2': value}]
    """

    nested_regions = general_extractor(campaign_metadata, 'LocationKeywords')

    # json.dumps allows us to take the set of the dictionaries
    # the list comprehension is unpacking the nested entries
    regions_json = set([json.dumps(region)
                    for region_list in nested_regions
                        for region in region_list])
    regions_dict = [json.loads(region) for region in regions_json]

    return regions_dict


def extract_collection_periods(campaign_metadata):
    """Extracts platforms as a proxy for collection_periods and aggregates the metadata

    Args:
        campaign_metadata (dict): this is a custom dict generated by campagin_xml_json

    Returns:
        dict: A dict containing each unique platform and its aggregated metadata, including
            DOIs, short and long names, platform identifiers, and instruments.
    """

    platforms = {}
    for data_product in campaign_metadata:
        print(data_product)

        # TODO: refactor the error handling in this loop 
        for platform_info in data_product['metadata'].get('Platforms', [{}]):
            # generate reference name
            platform_short_name = platform_info.get('ShortName', '')
            platform_long_name = platform_info.get('LongName', '')

            platform_chars = data_product['metadata']['Platforms'][0].get('Characteristics', [])
            platform_identifiers = [char.get('Value', '') for char in platform_chars if char.get('Name') == 'AircraftID']

            platform_reference = '_&_'.join([platform_short_name, platform_long_name] + platform_identifiers)

            # get instruments
            instruments = {}
            if platform_info.get('Instruments'):
                for instrument_info in platform_info.get('Instruments', []):
                    instrument_short_name = instrument_info.get('ShortName', '')
                    instrument_long_name = instrument_info.get('LongName', '')
                    instrument_reference = '_&_'.join([instrument_short_name, instrument_long_name])

                    instruments[instrument_reference] = {
                        'short_name': instrument_short_name,
                        'long_name': instrument_long_name,
                    }

            if platforms.get(platform_reference):
                platforms[platform_reference]['instruments'] = {
                    **platforms[platform_reference]['instruments'],
                    **instruments}
                platforms[platform_reference]['dois'].append(data_product.get('metadata',{}).get('DOI'))

            else:
                platforms[platform_reference] = {
                    'platform_names': {
                        'short_name': platform_short_name,
                        'long_name': platform_long_name},
                    'platform_identifiers': platform_identifiers,
                    'instrument_information_source': 'cmr_api',
                    'auto_generated': True,
                    'instruments': instruments,
                    'dois': [data_product.get('metadata',{}).get('DOI')]
                }

    return platforms


def date_overlap(cmr_start, cmr_end, dep_start, dep_end):
    """Takes two date ranges and returns the number of days of overlap.

    Args:
        cmr_start (datetime): Start date for CMR data
        cmr_end (datetime): End date for CMR data
        dep_start (datetime): Start date for deployment
        dep_end (datetime): End date for deployment

    Returns:
        int: Number of days of overlap of the two date ranges, or 0 if None.
    """

    Range = namedtuple('Range', ['start', 'end'])

    cmr_range = Range(start=cmr_start, end=cmr_end)
    dep_range = Range(start=dep_start, end=dep_end)

    latest_start = max(cmr_range.start, dep_range.start)
    earliest_end = min(cmr_range.end, dep_range.end)

    delta = (earliest_end - latest_start).days + 1
    overlap = max(0, delta)

    return overlap


def date_filter(campaign_metadata, dep_start, dep_end):
    """This function is intended to filter the returned CMR metadata based on a
        date range. It is expected to be used to generate deployment metadata, since
        CMR does not distinguish deployments and the user must input this data.

    Args:
        campaign_metadata (dict): this is a custom dict generated by campagin_xml_json
        dep_start (datetime): Start date for deployment
        dep_end (datetime): End date for deployment

    Returns:
        dict: This is a filtered version of the original metadata given to the function.
    """

    date_format = '%Y-%m-%dT%H:%M:%S.%fZ'

    filtered_metadata = []
    for reference in campaign_metadata:
        TemporalExtents = reference['metadata'].get('TemporalExtents', [{}])[0]
        cmr_start = TemporalExtents.get('RangeDateTimes', [{}])[0].get('BeginningDateTime', 'error')
        cmr_end = TemporalExtents.get('RangeDateTimes', [{}])[0].get('EndingDateTime', 'error')

        if cmr_start == 'error' or cmr_end == 'error':
            print('        ', reference['concept_id'], 'failed')
            continue
        else:
            print('        ', reference['concept_id'], 'success')            


        cmr_start = datetime.strptime(cmr_start, date_format)
        cmr_end = datetime.strptime(cmr_end, date_format)

        days_overlapping = date_overlap(cmr_start, cmr_end, dep_start, dep_end)
        if days_overlapping > 0:
            filtered_metadata.append(reference)

    return filtered_metadata


def project_filter(campaign_metadata, short_name):
    """Filters the campaign_metadata on a given project short_name.

    Args:
        campaign_metadata (dict): this is a custom dict generated by campagin_xml_json
        short_name (str): Project short name

    Returns:
        dict: This is a filtered version of the original metadata given to the function.
    """
    # TODO: does it make sense to use any()?
    filtered_metadata = []
    for reference in campaign_metadata:
        projects = reference['metadata'].get('Projects', [])
        for project in projects:
            project_short_name = project.get('ShortName', '')
            if short_name.lower() == project_short_name.lower():
                filtered_metadata.append(reference)
                break
    return filtered_metadata


def combine_spatial_extents(spatial_extents):
    # TODO: this should combine multiple spatial extents into a total coverage 
    pass


def get_concepts(campaign_metadata, dep_start, dep_end):
    filtered_metadata = date_filter(campaign_metadata, dep_start, dep_end)

    concepts = []
    for concept in filtered_metadata:
        concept_short = concept['metadata']['ShortName']
        doi = concept['metadata'].get('DOI',{}).get('DOI')
        if not(doi):
            continue    
        print(concept_short, doi)

        
        data = {
            'short_name': concept_short,
            'doi': concept_short,
            'platforms':[]
        }
        
        for cmr_plat in concept['metadata'].get('Platforms', []):
            cmr_plat_short = cmr_plat.get('ShortName')
            if cmr_plat_short:
                data['platforms'].append({cmr_plat_short: {'instruments':list(set([cmr_inst.get('ShortName') for cmr_inst in cmr_plat.get('Instruments', [])]))}})
                
                
        concepts.append(data) 

    return concepts